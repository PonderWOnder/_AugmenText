Research Question:
The continues improvement of artificial intelligence systems, is a process of guided evolution. Systems are thought up, implemented and tested. While testing not anticipated behaviour that results in misclassification is discovered and therefore leads to reconceptualization of the entire system. Though these systems are branded intelligent, the direct identification of misbehaviour is none of their features. More so they rely on the human ability to formulate an experiment to determine if their output does in fact represent reality. While it is also true that the underlying concept is an automatically tuning self-taught experiment, its parameters are chosen by the user and are not changeable in a dynamic way without destroying before acquired knowledge. The metaphor of a river, on its way to the ocean, is applicable. It wonâ€™t change course and starts running up a hill if it encounters a valley. In a case like this human intuition is necessary to guide the network to find information within the provided Data. To this day there is no mechanism that would emulate human intuition in a way, that it could be useable in automating artificial intelligence systems to a point where they are able to externalize assumption of their own properties so it could optimize itself to a given task, by reducing predictions mistakes which would resemble true intelligence. Even worst, if mistakes are not identified by the user such shortcomings, depending on the field of application, could endanger human lives.
Considering further development of artificial intelligence systems, continues improvements are made, which allow AI evolution to reach deeper levels of testing so it can find more accurate representations of reality. Foremost there is reinforcement learning which applies, in terms of human metrics, a simple concept of learning. Actions that are deemed positive reinforce structures within the network. This is achieved by splitting the network into two components one the propose an experiment and one that evaluates the outcome. By this mechanism it is possible to use a trial and error method, which does not need a completely new concept, if the network is presented a previously unseen set of information. Although this is a big advantage it is not possible for the network to change parameters in the underlying concept.
So, it is still the job of the user to analyse the results and determine if they are within the anticipated spectrum of values or show signs of misbehaviour. That is why it is necessary, to be able to show the inner workings of a network to the upmost precision. The better a system can be manipulated, the better it is understood and that is why it is as important, to be able to falsify results, as it is in any other science, so they can be proven to be right or wrong. Therefore, this paper is attempting to find most modern attack methods for neural networks and analyse them in context of their applicability in the field of explainable AI. A special focus shall be laid on their ability to illustrate the working of specific neural nets, in the realm of sematic segmentation, as well as their appropriateness in use to automate optimization of neural classifiers. 
